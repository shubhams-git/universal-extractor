import os
import pathlib
import logging
import json
import argparse
import sys
import glob
import mimetypes
from google import genai
from google.genai import types
from excel_to_pdf import ExcelToPdfService
from word_to_pdf import WordToPdfService
from typing import Optional, Dict, Any, Tuple, Union, List
import shutil

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)


class UniversalFileProcessor:
    """
    Universal file processor that handles any file type with Gemini 2.5 Pro.
    Uses latest Google GenAI SDK with structured output and native file support.
    """
    
    # File type categories
    EXCEL_TYPES = {'.xlsx', '.xls', '.xlsm', '.xlsb'}
    PDF_TYPES = {'.pdf'}
    WORD_TYPES = {'.docx', '.doc'}
    TEXT_TYPES = {'.txt', '.csv', '.tsv', '.json', '.xml', '.html', '.md', '.rtf'}
    IMAGE_TYPES = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}
    
    # Gemini native support (no conversion needed)
    NATIVE_TYPES = PDF_TYPES | IMAGE_TYPES | TEXT_TYPES
    
    def __init__(self, api_key: Optional[str] = None):
        """Initialize the file processor with Gemini 2.5 Pro."""
        self.logger = logging.getLogger(__name__)
        
        # Initialize Gemini client with latest SDK
        try:
            self.gemini_client = genai.Client(api_key=api_key)
            self.logger.info("‚úÖ Gemini 2.5 Pro client initialized successfully")
        except Exception as e:
            self.logger.error(f"‚ùå Failed to initialize Gemini client: {e}")
            raise
        
        # Initialize conversion services (only for non-native types)
        self.excel_service = self._init_excel_service()
        self.word_service = self._init_word_service()
        
        # Default extraction prompt optimized for Gemini 2.5 Pro
        self.default_prompt = """
Extract all meaningful content from this file into a well-structured JSON format.

**EXTRACTION GUIDELINES:**
1. **Data Quality**: Focus on actual content, ignore formatting artifacts
2. **Structure Preservation**: Maintain logical relationships and hierarchies  
3. **Accuracy**: Ensure numerical precision, especially for financial data
4. **Clean Output**: Remove autogenerated content (headers/footers like 'Created with Aspose.Cells')
5. **Completeness**: Extract all meaningful data including tables, lists, and text

**OUTPUT REQUIREMENTS:**
- Must be valid JSON starting with '{' and ending with '}'
- Organize data logically based on content type (tables, paragraphs, metadata, etc.)
- Use descriptive keys that reflect the actual content structure
- High accuracy in data extraction is critical

**CONTENT-SPECIFIC INSTRUCTIONS:**
- For spreadsheets: Extract all sheets, formulas, calculated values
- For documents: Preserve structure (headings, paragraphs, lists, tables)
- For images: Describe visual content, extract any visible text
- For forms: Extract field names and values clearly
"""
    
    def _init_excel_service(self) -> Optional[ExcelToPdfService]:
        """Initialize Excel service if available."""
        try:
            service = ExcelToPdfService()
            self.logger.info("‚úÖ Excel processing service available")
            return service
        except ImportError as e:
            self.logger.warning(f"‚ö†Ô∏è Excel processing disabled: {e}")
            self.logger.info("üí° Install with: pip install aspose-cells-python")
            return None
    
    def _init_word_service(self) -> Optional[WordToPdfService]:
        """Initialize Word service if available."""
        try:
            service = WordToPdfService()
            self.logger.info("‚úÖ Word processing service available")
            return service
        except ImportError as e:
            self.logger.warning(f"‚ö†Ô∏è Word processing disabled: {e}")
            self.logger.info("üí° Install with: pip install reportlab docx2txt python-docx")
            return None
    
    def detect_file_type(self, file_path: str) -> Tuple[str, str]:
        """
        Detect file type and MIME type.
        
        Args:
            file_path: Path to the file
            
        Returns:
            Tuple of (file_extension, mime_type)
        """
        file_path_obj = pathlib.Path(file_path)
        extension = file_path_obj.suffix.lower()
        
        # Get MIME type
        mime_type, _ = mimetypes.guess_type(file_path)
        
        # Fallback MIME detection for common types
        if mime_type is None:
            mime_type = self._detect_mime_from_extension(extension)
        
        self.logger.info(f"üìÑ Detected file: {extension}, MIME: {mime_type}")
        return extension, mime_type
    
    def _detect_mime_from_extension(self, extension: str) -> str:
        """Fallback MIME type detection from extension."""
        mime_map = {
            '.pdf': 'application/pdf',
            '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            '.xls': 'application/vnd.ms-excel',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.doc': 'application/msword',
            '.txt': 'text/plain',
            '.csv': 'text/csv',
            '.json': 'application/json',
            '.xml': 'application/xml',
            '.html': 'text/html',
            '.md': 'text/markdown',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.bmp': 'image/bmp',
            '.tiff': 'image/tiff',
            '.webp': 'image/webp'
        }
        return mime_map.get(extension, 'application/octet-stream')
    
    def get_file_category(self, extension: str) -> str:
        """Categorize file based on extension."""
        if extension in self.EXCEL_TYPES:
            return "excel"
        elif extension in self.PDF_TYPES:
            return "pdf"
        elif extension in self.WORD_TYPES:
            return "word"
        elif extension in self.TEXT_TYPES:
            return "text"
        elif extension in self.IMAGE_TYPES:
            return "image"
        else:
            return "unknown"
    
    def needs_conversion(self, extension: str) -> bool:
        """Check if file needs conversion to PDF for processing."""
        return extension not in self.NATIVE_TYPES
    
    def convert_to_pdf(self, file_path: str, category: str, temp_dir: str = "temp") -> Optional[str]:
        """
        Convert file to PDF if needed.
        
        Args:
            file_path: Input file path
            category: File category
            temp_dir: Temp directory for PDF output
            
        Returns:
            Path to PDF file or original file if conversion not needed
        """
        pathlib.Path(temp_dir).mkdir(parents=True, exist_ok=True)
        
        input_filename = pathlib.Path(file_path).stem
        pdf_path = pathlib.Path(temp_dir) / f"{input_filename}.pdf"
        
        try:
            if category == "excel":
                if not self.excel_service:
                    self.logger.error("‚ùå Excel service not available - install aspose-cells-python")
                    return None
                    
                success = self.excel_service.convert_excel_to_pdf(
                    excel_path=file_path,
                    pdf_path=str(pdf_path),
                    recalculate_formulas=True
                )
                return str(pdf_path) if success else None
                
            elif category == "word":
                if not self.word_service:
                    self.logger.error("‚ùå Word service not available - install required dependencies")
                    return None
                    
                success = self.word_service.convert_word_to_pdf(
                    file_path, str(pdf_path)
                )
                return str(pdf_path) if success else None
                
            elif category in ["pdf", "text", "image"]:
                # Native support - no conversion needed
                return file_path
                
            else:
                self.logger.error(f"‚ùå Unsupported file category: {category}")
                return None
                
        except Exception as e:
            self.logger.error(f"‚ùå Error converting {file_path}: {e}")
            return None
    
    def extract_with_gemini(self, file_path: str, mime_type: str, output_dir: str, 
                          filename: str, prompt: Optional[str] = None) -> Optional[str]:
        """
        Extract data using Gemini 2.5 Pro with latest SDK patterns.
        
        Args:
            file_path: Path to file (PDF, image, text) or converted PDF
            mime_type: MIME type of the file
            output_dir: Output directory
            filename: Original filename
            prompt: Custom prompt
            
        Returns:
            Path to JSON file or None if failed
        """
        try:
            self.logger.info(f"üß† Starting Gemini 2.5 Pro extraction: {file_path}")
            
            extraction_prompt = prompt if prompt is not None else self.default_prompt
            
            file_obj = pathlib.Path(file_path)
            if not file_obj.exists():
                self.logger.error(f"‚ùå File not found: {file_path}")
                return None
            
            # Read file content
            file_data = file_obj.read_bytes()
            
            # Create content for Gemini 2.5 Pro using latest SDK patterns
            self.logger.info("üöÄ Calling Gemini 2.5 Pro API with structured output...")
            
            response = self.gemini_client.models.generate_content(
                model="gemini-2.5-flash", 
                contents=[
                    types.Part.from_bytes(
                        data=file_data,
                        mime_type=mime_type,
                    ),
                    extraction_prompt
                ],
                config=types.GenerateContentConfig(
                    response_mime_type='application/json',  # Enforce JSON output - latest SDK syntax
                    temperature=0.1,  # Low temperature for consistency
                    thinking_config=types.ThinkingConfig(thinking_budget=1024)  # Enable thinking for better reasoning
                ),
            )
            
            if response.text:
                try:
                    # Parse and validate JSON
                    json_data = json.loads(response.text)
                    
                    # Validate it's meaningful data
                    if not json_data or not isinstance(json_data, (dict, list)):
                        self.logger.error("‚ùå Invalid JSON structure received")
                        return None
                    
                    json_filename = f"{filename}_extracted.json"
                    json_path = pathlib.Path(output_dir) / json_filename
                    
                    # Save with proper formatting
                    with open(json_path, 'w', encoding='utf-8') as f:
                        json.dump(json_data, f, ensure_ascii=False, indent=2)
                    
                    self.logger.info(f"‚úÖ Successfully extracted to: {json_path}")
                    return str(json_path)
                    
                except json.JSONDecodeError as e:
                    self.logger.error(f"‚ùå Failed to parse JSON response: {e}")
                    self.logger.debug(f"Response text: {response.text[:500]}...")
                    return None
                except Exception as e:
                    self.logger.error(f"‚ùå Error saving JSON: {e}")
                    return None
            else:
                self.logger.warning("‚ö†Ô∏è Empty response from Gemini 2.5 Pro")
                return None
                
        except Exception as e:
            self.logger.error(f"‚ùå Gemini extraction error: {e}")
            return None


class UniversalDataExtractor:
    """
    Main orchestrator for universal data extraction with Gemini 2.5 Pro.
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """Initialize the data extractor."""
        self.logger = logging.getLogger(__name__)
        
        self.processor = UniversalFileProcessor(api_key=api_key)
        self.temp_dir = "temp"
        self.output_dir = "output"
    
    def process(self, file_path: str, prompt: Optional[str] = None) -> Optional[str]:
        """
        Process any file type for data extraction.
        
        Args:
            file_path: Input file path
            prompt: Custom extraction prompt
            
        Returns:
            Path to JSON output or None if failed
        """
        self.logger.info(f"üìÅ Processing: {file_path}")
        
        try:
            # Detect file type
            extension, mime_type = self.processor.detect_file_type(file_path)
            category = self.processor.get_file_category(extension)
            
            self.logger.info(f"üìã File analysis - Extension: {extension}, MIME: {mime_type}, Category: {category}")
            
            # Determine if conversion is needed
            needs_conversion = self.processor.needs_conversion(extension)
            processed_file = file_path
            cleanup_file = None
            
            if needs_conversion:
                self.logger.info(f"üîÑ Converting {category} file to PDF for processing...")
                processed_file = self.processor.convert_to_pdf(
                    file_path=file_path,
                    category=category,
                    temp_dir=self.temp_dir
                )
                
                if processed_file is None:
                    self.logger.error(f"‚ùå Failed to convert to PDF: {file_path}")
                    return None
                
                # Update MIME type for converted PDF
                mime_type = 'application/pdf'
                cleanup_file = processed_file  # Mark for cleanup
                self.logger.info(f"‚úÖ Converted to PDF: {processed_file}")
            else:
                self.logger.info(f"‚ö° Using native Gemini 2.5 Pro support for {category} file")
            
            # Extract with Gemini 2.5 Pro
            pathlib.Path(self.output_dir).mkdir(parents=True, exist_ok=True)
            original_filename = pathlib.Path(file_path).stem
            
            json_path = self.processor.extract_with_gemini(
                file_path=processed_file,
                mime_type=mime_type,
                output_dir=self.output_dir,
                filename=original_filename,
                prompt=prompt
            )
            
            # Clean up temporary PDF if created
            if cleanup_file and cleanup_file != file_path and os.path.exists(cleanup_file):
                os.remove(cleanup_file)
                self.logger.info(f"üßπ Cleaned temp file: {cleanup_file}")
            
            if json_path:
                self.logger.info(f"üéâ Successfully processed: {json_path}")
                return json_path
            else:
                self.logger.error("‚ùå Gemini extraction failed")
                return None
                
        except Exception as e:
            self.logger.error(f"‚ùå Processing error: {e}")
            return None
    
    def batch_process(self, file_paths: List[str], prompt: Optional[str] = None) -> Dict[str, Any]:
        """
        Process multiple files.
        
        Args:
            file_paths: List of file paths
            prompt: Custom extraction prompt
            
        Returns:
            Processing results summary
        """
        results = {
            "successful": [],
            "failed": [],
            "total_files": len(file_paths),
            "success_count": 0,
            "failure_count": 0
        }
        
        for file_path in file_paths:
            try:
                result = self.process(file_path, prompt)
                if result:
                    results["successful"].append({
                        "input_file": file_path,
                        "output_file": result
                    })
                    results["success_count"] += 1
                else:
                    results["failed"].append({
                        "file": file_path,
                        "error": "Processing failed"
                    })
                    results["failure_count"] += 1
            except Exception as e:
                results["failed"].append({
                    "file": file_path,
                    "error": str(e)
                })
                results["failure_count"] += 1
        
        return results


def main():
    """Main execution with argument handling."""
    
    def setup_parser():
        """Setup argument parser."""
        parser = argparse.ArgumentParser(
            description="Universal Data Extractor - Process any file type with Gemini 2.5 Pro",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
Examples:
  python main.py input/report.pdf
  python main.py input/data.xlsx input/document.docx
  python main.py "input/*.*" --prompt "Extract financial data"
  python main.py input/image.png -v
            """
        )
        
        parser.add_argument(
            'files',
            nargs='+',
            help='Files to process (PDF, Excel, Word, images, text files)'
        )
        
        parser.add_argument(
            '-v', '--verbose',
            action='store_true',
            help='Verbose logging'
        )
        
        parser.add_argument(
            '--prompt',
            help='Custom extraction prompt for Gemini 2.5 Pro'
        )
        
        parser.add_argument(
            '--api-key',
            help='Gemini API key (or set GOOGLE_API_KEY environment variable)'
        )
        
        return parser
    
    def setup_logging(verbose=False):
        """Setup logging."""
        level = logging.DEBUG if verbose else logging.INFO
        logging.basicConfig(
            level=level,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        return logging.getLogger(__name__)
    
    def expand_files(patterns):
        """Expand file patterns and validate files."""
        files = []
        for pattern in patterns:
            if '*' in pattern or '?' in pattern:
                matches = glob.glob(pattern)
                if matches:
                    files.extend(matches)
                else:
                    print(f"‚ö†Ô∏è  No matches for: {pattern}")
            else:
                if os.path.exists(pattern):
                    files.append(pattern)
                else:
                    print(f"‚ö†Ô∏è  File not found: {pattern}")
        return files
    
    def get_api_key(args_api_key):
        """Get API key from arguments or environment."""
        if args_api_key:
            return args_api_key
        
        api_key = os.getenv('GOOGLE_API_KEY') or os.getenv('GEMINI_API_KEY')
        if not api_key:
            print("‚ùå Error: No API key found")
            print("üí° Set GOOGLE_API_KEY environment variable or use --api-key")
            print("   Get your API key from: https://aistudio.google.com/app/apikey")
            sys.exit(1)
        
        return api_key
    
    # Parse arguments
    parser = setup_parser()
    args = parser.parse_args()
    
    # Setup logging
    logger = setup_logging(args.verbose)
    
    # Header
    print("üöÄ Universal Data Extractor v3.0")
    print("üß† Powered by Gemini 2.5 Pro with structured output")
    print("üìÅ Supports: PDF, Excel, Word, Images, Text files")
    print(f"üìÇ Output: {pathlib.Path('output').resolve()}")
    print(f"üìÇ Temp: {pathlib.Path('temp').resolve()}")
    if args.prompt:
        print(f"üìù Custom prompt: {args.prompt[:80]}{'...' if len(args.prompt) > 80 else ''}")
    print("-" * 60)
    
    try:
        # Get API key
        api_key = get_api_key(args.api_key)
        
        # Initialize extractor
        logger.info("Initializing Universal Data Extractor...")
        extractor = UniversalDataExtractor(api_key=api_key)
        print("‚úÖ Data Extractor ready with Gemini 2.5 Pro")
        
    except Exception as e:
        print(f"‚ùå Initialization failed: {e}")
        logger.error(f"Init error: {e}", exc_info=True)
        sys.exit(1)
    
    # Process files
    files = expand_files(args.files)
    
    if not files:
        print("‚ùå No files found")
        sys.exit(1)
    
    print(f"üìã Processing {len(files)} file(s):")
    for i, file in enumerate(files, 1):
        try:
            size_mb = pathlib.Path(file).stat().st_size / (1024 * 1024)
            print(f"   {i}. {file} ({size_mb:.2f} MB)")
        except:
            print(f"   {i}. {file} (size unknown)")
    print("-" * 60)
    
    # Process each file
    if len(files) == 1:
        # Single file processing
        file = files[0]
        print(f"üìÑ Processing: {file}")
        
        try:
            result = extractor.process(
                file_path=file,
                prompt=args.prompt
            )
            
            if result:
                print(f"‚úÖ SUCCESS: {file}")
                print(f"   üìÑ Output: {result}")
                print(f"\nüéâ Processing complete!")
                sys.exit(0)
            else:
                print(f"‚ùå FAILED: {file}")
                sys.exit(1)
                
        except Exception as e:
            print(f"‚ùå ERROR: {file} - {e}")
            logger.error(f"Error processing {file}: {e}", exc_info=True)
            sys.exit(1)
    
    else:
        # Batch processing
        try:
            results = extractor.batch_process(files, args.prompt)
            
            # Summary
            print("\n" + "=" * 60)
            print("üìä PROCESSING SUMMARY")
            print("=" * 60)
            print(f"üìà Total: {results['total_files']}")
            print(f"‚úÖ Success: {results['success_count']}")
            print(f"‚ùå Failed: {results['failure_count']}")
            
            if results["successful"]:
                print(f"\nüéØ Successful extractions:")
                for item in results["successful"]:
                    print(f"  ‚Ä¢ {item['input_file']} ‚Üí {item['output_file']}")
                print(f"\nüìÅ JSON outputs in: {pathlib.Path('output').resolve()}")
            
            if results["failed"]:
                print(f"\n‚ö†Ô∏è  Failed extractions:")
                for item in results["failed"]:
                    print(f"  ‚Ä¢ {item['file']}: {item['error']}")
            
            # Exit code
            if results['failure_count'] > 0:
                print(f"\n‚ö†Ô∏è  {results['failure_count']} file(s) failed")
                sys.exit(1)
            else:
                print(f"\nüéâ All {results['success_count']} file(s) processed successfully!")
                sys.exit(0)
                
        except Exception as e:
            print(f"‚ùå Batch processing error: {e}")
            logger.error(f"Batch processing error: {e}", exc_info=True)
            sys.exit(1)


if __name__ == "__main__":
    main()